{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT_Fine_Tuning.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9f64fc49c068491cbbec554c7ea39baa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_5a3d02a754bc485aad5162032e6992ec","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_88b222412b7d4789a5fdf283951521cd","IPY_MODEL_fbb91c0ac5c64cf68543953c1f3537d8"]}},"5a3d02a754bc485aad5162032e6992ec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88b222412b7d4789a5fdf283951521cd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_9ed84137b79b43408b6ec2f3de765e8f","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_afadbd8d321f43eeb93d02b415f8c0eb"}},"fbb91c0ac5c64cf68543953c1f3537d8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_279e18e76e4a45fd97d870fe17ed2354","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 582kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_dfbcde0543be4adca59480e3abce52b8"}},"9ed84137b79b43408b6ec2f3de765e8f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"afadbd8d321f43eeb93d02b415f8c0eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"279e18e76e4a45fd97d870fe17ed2354":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"dfbcde0543be4adca59480e3abce52b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"248311ede4e541ceb3082e7752661f05":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7aabddb88b7d4722bae2540aebb388d2","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_0d51539520284e78882fbeeb3f1f56e2","IPY_MODEL_7401a77c1a7b486f97ea6ed4aa657cb4"]}},"7aabddb88b7d4722bae2540aebb388d2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0d51539520284e78882fbeeb3f1f56e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8332db653ee742b7831cd74334245298","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_6e3ccd852baf4f9fbc2ab7dc2a51f974"}},"7401a77c1a7b486f97ea6ed4aa657cb4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_00c2b8e3af06495a8226b499fc7071af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:09&lt;00:00, 43.9B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c73d3a4100284f3eb3e2aeb47a56b644"}},"8332db653ee742b7831cd74334245298":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"6e3ccd852baf4f9fbc2ab7dc2a51f974":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"00c2b8e3af06495a8226b499fc7071af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c73d3a4100284f3eb3e2aeb47a56b644":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"08d6c7b28ee94cee940676576bf93b29":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7858608c72974dec8eefa468f3558a70","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8f90b1fececd4cb98f4accd5c831f33d","IPY_MODEL_f3a75330bcd1480ab6f052e2fdeef417"]}},"7858608c72974dec8eefa468f3558a70":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8f90b1fececd4cb98f4accd5c831f33d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3769572171134fdb9567b03bde03cca9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2e4b63dd5def493b88c5d68147ab25fe"}},"f3a75330bcd1480ab6f052e2fdeef417":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4d30dd9290914746aa0a9bffa7b5c3ba","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 440M/440M [00:09&lt;00:00, 45.3MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1604aab037eb44dfb3fabbe5d8106000"}},"3769572171134fdb9567b03bde03cca9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2e4b63dd5def493b88c5d68147ab25fe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4d30dd9290914746aa0a9bffa7b5c3ba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"1604aab037eb44dfb3fabbe5d8106000":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"BJR6t_gCQe_x","colab_type":"text"},"source":["This post is presented in two forms--as a blog post [here](http://mccormickml.com/2019/07/22/BERT-fine-tuning/) and as a Colab Notebook [here](https://colab.research.google.com/drive/1Y4o3jh3ZH70tl6mCd76vz_IxX23biCPP). \n","\n","I've also published a video walkthrough of this post on my YouTube channel! [Part 1](https://youtu.be/x66kkDnbzi4) and [Part 2](https://youtu.be/Hnvb9b7a_Ps).\n","\n"]},{"cell_type":"code","metadata":{"id":"PaHW6K45v3Cp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1594279274079,"user_tz":-330,"elapsed":51358,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"52e8afa7-ff9e-4d0e-c6d6-e4ae57c5a5cd"},"source":["# Mount Google Drive to this Notebook instance.\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DEfSbAA4QHas","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594279282881,"user_tz":-330,"elapsed":14621,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"1f682b0a-eb27-4bfa-c688-168d2a78450c"},"source":["import tensorflow as tf\n","# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oYsV4H8fCpZ-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1594279286117,"user_tz":-330,"elapsed":16495,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"0adb3f23-7856-40ee-bb7e-1dd3851324e4"},"source":["\n","import torch\n","\n","# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":3,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla K80\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0NmMdkZO8R6q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"status":"ok","timestamp":1594279294287,"user_tz":-330,"elapsed":24204,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"f8633aa9-ff14-45dc-d998-2907818cf947"},"source":["!pip install transformers"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n","\u001b[K     |████████████████████████████████| 778kB 6.4MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 18.5MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 38.5MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Collecting tokenizers==0.8.1.rc1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/d0/30d5f8d221a0ed981a186c8eb986ce1c94e3a6e87f994eae9f4aa5250217/tokenizers-0.8.1rc1-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n","\u001b[K     |████████████████████████████████| 3.0MB 41.3MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=9c729bca4e5f2d617328659f84b80af2dd43fe91feb5df1c0297ea5650c69a8a\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, sentencepiece, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_UkeC7SG2krJ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282440547,"user_tz":-330,"elapsed":2001,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["import pandas as pd\n","\n","# Load the dataset into a pandas dataframe.\n","df = pd.read_csv(\"/content/gdrive/My Drive/Multi_Task_Learning/PangLee/polarity_data/sentiment.csv\")\n"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"c1coqN3hbglp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1594282440551,"user_tz":-330,"elapsed":1518,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"d0bcb3e3-9e8c-4214-f9d7-152b2a147055"},"source":["df"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>text</th>\n","      <th>pos</th>\n","      <th>neg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>the rock destined the 21st century new conan a...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>the gorgeously elaborate continuation the lord...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>effective but too tepid biopic</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>you sometimes like the movies have fun wasabi ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>emerges something rare issue movie that honest...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10657</th>\n","      <td>10657</td>\n","      <td>terrible movie that some people will neverthel...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10658</th>\n","      <td>10658</td>\n","      <td>there are many definitions time waster but thi...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10659</th>\n","      <td>10659</td>\n","      <td>stands crocodile hunter has the hurried badly ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10660</th>\n","      <td>10660</td>\n","      <td>the thing looks like made for home video quickie</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10661</th>\n","      <td>10661</td>\n","      <td>enigma well made but just too dry and too placid</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10662 rows × 4 columns</p>\n","</div>"],"text/plain":["       Unnamed: 0                                               text  pos  neg\n","0               0  the rock destined the 21st century new conan a...    1    0\n","1               1  the gorgeously elaborate continuation the lord...    1    0\n","2               2                     effective but too tepid biopic    1    0\n","3               3  you sometimes like the movies have fun wasabi ...    1    0\n","4               4  emerges something rare issue movie that honest...    1    0\n","...           ...                                                ...  ...  ...\n","10657       10657  terrible movie that some people will neverthel...    0    1\n","10658       10658  there are many definitions time waster but thi...    0    1\n","10659       10659  stands crocodile hunter has the hurried badly ...    0    1\n","10660       10660  the thing looks like made for home video quickie     0    1\n","10661       10661  enigma well made but just too dry and too placid     0    1\n","\n","[10662 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"khAKcR14wrCh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282454372,"user_tz":-330,"elapsed":1107,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["df = df[['text', 'pos', 'neg']]"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"_x3gdzBlo7u4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282486279,"user_tz":-330,"elapsed":1152,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["pos = df[df['pos']==1]"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"I56tnZY_pEPj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282502306,"user_tz":-330,"elapsed":1140,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["neg = df[df['neg']==1]"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"FqVC0BDopHFx","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282523703,"user_tz":-330,"elapsed":1225,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["pos = pos.sample(n = 5000)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"YdXxNCMJpMIC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282535810,"user_tz":-330,"elapsed":1097,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["neg = neg.sample(n = 5000)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"HGRDj9xKpPFq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282552703,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["dataset = pd.concat([pos,neg])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Gzj7evfpTRt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282594257,"user_tz":-330,"elapsed":1154,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["dataset.to_csv(\"/content/gdrive/My Drive/Multi_Task_Learning/PangLee/polarity_data/sentiment_10k.csv\")"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z474sSC6oe7A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":82,"referenced_widgets":["9f64fc49c068491cbbec554c7ea39baa","5a3d02a754bc485aad5162032e6992ec","88b222412b7d4789a5fdf283951521cd","fbb91c0ac5c64cf68543953c1f3537d8","9ed84137b79b43408b6ec2f3de765e8f","afadbd8d321f43eeb93d02b415f8c0eb","279e18e76e4a45fd97d870fe17ed2354","dfbcde0543be4adca59480e3abce52b8"]},"executionInfo":{"status":"ok","timestamp":1594279300024,"user_tz":-330,"elapsed":3223,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"8a4d1872-b065-4cd6-916f-826f2fc2d9a8"},"source":["from transformers import BertTokenizer\n","\n","# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9f64fc49c068491cbbec554c7ea39baa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jdWNxI3P9MKc","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594279300025,"user_tz":-330,"elapsed":3210,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["import transformers as ppb"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"gFsCTp_mporB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":114,"referenced_widgets":["248311ede4e541ceb3082e7752661f05","7aabddb88b7d4722bae2540aebb388d2","0d51539520284e78882fbeeb3f1f56e2","7401a77c1a7b486f97ea6ed4aa657cb4","8332db653ee742b7831cd74334245298","6e3ccd852baf4f9fbc2ab7dc2a51f974","00c2b8e3af06495a8226b499fc7071af","c73d3a4100284f3eb3e2aeb47a56b644","08d6c7b28ee94cee940676576bf93b29","7858608c72974dec8eefa468f3558a70","8f90b1fececd4cb98f4accd5c831f33d","f3a75330bcd1480ab6f052e2fdeef417","3769572171134fdb9567b03bde03cca9","2e4b63dd5def493b88c5d68147ab25fe","4d30dd9290914746aa0a9bffa7b5c3ba","1604aab037eb44dfb3fabbe5d8106000"]},"executionInfo":{"status":"ok","timestamp":1594279313988,"user_tz":-330,"elapsed":17157,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"8fceb558-adb4-4367-c7d7-a01532a27bc6"},"source":["# from transformers import BertForSequenceClassification, AdamW, BertConfig\n","model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer,'bert-base-uncased')\n","\n","tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n","model = model_class.from_pretrained(pretrained_weights)\n"],"execution_count":10,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"248311ede4e541ceb3082e7752661f05","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"08d6c7b28ee94cee940676576bf93b29","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KtXhIz235xu2","colab_type":"code","colab":{}},"source":["# data = df[3000:4000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GuE5BqICAne2","colab_type":"code","colab":{}},"source":["# Get the lists of sentences and their labels.\n","# sentences = data.reviewText.values\n","# labels = data.Sentiment.values"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okdbq2N86KDn","colab_type":"code","colab":{}},"source":["# for i in range(len(labels)):\n","#   if labels[i] == 'positive':\n","#     labels[i] = 1\n","\n","#   elif labels[i] == 'neutral':\n","#     labels[i] =0\n","\n","#   else:\n","#     labels[i] = -1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2bBdb3pt8LuQ","colab_type":"code","colab":{}},"source":["# input_ids = []\n","\n","# # For every sentence...\n","# for sent in sentences:\n","\n","#     encoded_sent = tokenizer.encode(\n","#                         str(sent),                      # Sentence to encode.\n","#                         add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","#                         max_length = 128,          # Truncate all sentences.\n","#                         #return_tensors = 'pt',     # Return pytorch tensors.\n","#                    )\n","\n","#     input_ids.append(encoded_sent)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cp9BPRd1tMIo","colab_type":"code","colab":{}},"source":["# from keras.preprocessing.sequence import pad_sequences\n","\n","# MAX_LEN = 128\n","\n","# input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","#                           value=0, truncating=\"post\", padding=\"post\")\n","\n","# # print('\\nDone.')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cDoC24LeEv3N","colab_type":"code","colab":{}},"source":["# attention_masks = []\n","\n","# for sent in input_ids:\n","\n","#     att_mask = [int(token_id > 0) for token_id in sent]\n","\n","#     attention_masks.append(att_mask)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aFbE-UHvsb7-","colab_type":"code","colab":{}},"source":["\n","# from sklearn.model_selection import train_test_split\n","\n","\n","# train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels, \n","#                                                             random_state=2018, test_size=0.2)\n","\n","# train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n","#                                              random_state=2018, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jw5K2A5Ko1RF","colab_type":"code","colab":{}},"source":["\n","\n","# input_ids = torch.tensor(input_ids)\n","# # validation_inputs = torch.tensor(validation_inputs)\n","\n","# labels = torch.tensor(list(labels))\n","# # validation_labels = torch.tensor(list(validation_labels))\n","\n","# attention_masks = torch.tensor(attention_masks)\n","# validation_masks = torch.tensor(validation_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GEgLpFVlo1Z-","colab_type":"code","colab":{}},"source":["# from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","\n","\n","# batch_size = 32\n","\n","# # Create the DataLoader for our training set.\n","# train_data = TensorDataset(train_inputs, train_masks, train_labels)\n","# train_sampler = RandomSampler(train_data)\n","# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","# # Create the DataLoader for our validation set.\n","# validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n","# validation_sampler = SequentialSampler(validation_data)\n","# validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fXUg6L568Le9","colab_type":"code","colab":{}},"source":["# with torch.no_grad():\n","#     last_hidden_states = model(input_ids, attention_masks)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0n_44o0iK3D5","colab_type":"code","colab":{}},"source":["#For sentence classification, we’re only only interested in BERT’s output for the [CLS] token, so we select that slice of the cube and discard everything else."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IQ5bz2hp9ULW","colab_type":"code","colab":{}},"source":["# features = last_hidden_states[0][:,0,:].numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-pXxCNbdjuGt","colab_type":"code","colab":{}},"source":["# features_3d = last_hidden_states[0].numpy()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7RMIScV_Tbem","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282601524,"user_tz":-330,"elapsed":1724,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["import numpy as np"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"PkfT22k3m7mW","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282601528,"user_tz":-330,"elapsed":1436,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["# np.save('/content/gdrive/My Drive/Multi_Task_Learning/Bert_3d/bert_emb_4k.npy', features_3d)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"zC-wFKinv6Iv","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594282601530,"user_tz":-330,"elapsed":1044,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}}},"source":["from keras.preprocessing.sequence import pad_sequences"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"BoTFAAiidMQG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594282620163,"user_tz":-330,"elapsed":1102,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"b218d0c2-ddbf-4217-8cef-5797032a65e1"},"source":["len(dataset.text.values)"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["10000"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"nWfL64ZwqG-1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":402},"executionInfo":{"status":"ok","timestamp":1594282780525,"user_tz":-330,"elapsed":10198,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"7318966c-7d63-4155-cf2d-48b20d04c301"},"source":["dataset"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>pos</th>\n","      <th>neg</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1178</th>\n","      <td>story haven seen the big screen before and sto...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3186</th>\n","      <td>its best and does have some very funny sequenc...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4886</th>\n","      <td>high spirited buddy movie about the reunion be...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2151</th>\n","      <td>combine the paranoid claustrophobia submarine ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4958</th>\n","      <td>those who don entirely get godard distinctive ...</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>10208</th>\n","      <td>has the right approach and the right opening p...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6356</th>\n","      <td>simply doesn have sufficient heft justify its ...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8235</th>\n","      <td>here self congratulatory imax rah rah</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>10237</th>\n","      <td>with nary glimmer self knowledge crane becomes...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7149</th>\n","      <td>this isn even madonna swept away this her blue...</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10000 rows × 3 columns</p>\n","</div>"],"text/plain":["                                                    text  pos  neg\n","1178   story haven seen the big screen before and sto...    1    0\n","3186   its best and does have some very funny sequenc...    1    0\n","4886   high spirited buddy movie about the reunion be...    1    0\n","2151   combine the paranoid claustrophobia submarine ...    1    0\n","4958   those who don entirely get godard distinctive ...    1    0\n","...                                                  ...  ...  ...\n","10208  has the right approach and the right opening p...    0    1\n","6356   simply doesn have sufficient heft justify its ...    0    1\n","8235              here self congratulatory imax rah rah     0    1\n","10237  with nary glimmer self knowledge crane becomes...    0    1\n","7149   this isn even madonna swept away this her blue...    0    1\n","\n","[10000 rows x 3 columns]"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"W9fiMFlgpE4j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":521},"executionInfo":{"status":"ok","timestamp":1594284075843,"user_tz":-330,"elapsed":1287551,"user":{"displayName":"Shweta Pardeshi","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghek6fOOwyGa2MtKUifmPCFC6jImPSx1r0BU1vj=s64","userId":"00227288606050077025"}},"outputId":"a73cdb48-c668-47c7-aacf-fd2ec161c6b2"},"source":["for i in range(10):\n","  data = dataset[i*1000:(i+1)*1000]\n","\n","  sentences = data.text.values\n","  # labels = data.Sentiment.values\n","  input_ids = []\n","\n","  # For every sentence...\n","  for sent in sentences:\n","\n","      encoded_sent = tokenizer.encode(\n","                          str(sent),                      # Sentence to encode.\n","                          add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n","                          max_length = 45,          # Truncate all sentences.\n","                          truncation = True\n","                          #return_tensors = 'pt',     # Return pytorch tensors.\n","                    )\n","\n","      input_ids.append(encoded_sent)\n","\n","  MAX_LEN = 45\n","\n","  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n","                            value=0, truncating=\"post\", padding=\"post\")\n","\n","  attention_masks = []\n","\n","  for sent in input_ids:\n","\n","      att_mask = [int(token_id > 0) for token_id in sent]\n","\n","      attention_masks.append(att_mask)\n","\n","    \n","  input_ids = torch.tensor(input_ids)\n","\n","  # labels = torch.tensor(list(labels))\n","\n","  attention_masks = torch.tensor(attention_masks)\n","  print(\"Started\")\n","  with torch.no_grad():\n","      last_hidden_states = model(input_ids, attention_masks)\n","\n","  # features = last_hidden_states[0][:,0,:].numpy()\n","  features_3d = last_hidden_states[0].numpy()\n","  print(features_3d.shape)\n","  # np.save('/content/gdrive/My Drive/Multi_Task_Learning/Bert/bert_emb_{}k.npy'.format(i+1), features)\n","  np.save('/content/gdrive/My Drive/Multi_Task_Learning/PangLee/polarity_data/bert/bert_emb_{}k.npy'.format(i+1), features_3d)\n","  print('Done {} embeddings'.format(i+1))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Started\n","(1000, 45, 768)\n","Done 1 embeddings\n","Started\n","(1000, 45, 768)\n","Done 2 embeddings\n","Started\n","(1000, 45, 768)\n","Done 3 embeddings\n","Started\n","(1000, 45, 768)\n","Done 4 embeddings\n","Started\n","(1000, 45, 768)\n","Done 5 embeddings\n","Started\n","(1000, 45, 768)\n","Done 6 embeddings\n","Started\n","(1000, 45, 768)\n","Done 7 embeddings\n","Started\n","(1000, 45, 768)\n","Done 8 embeddings\n","Started\n","(1000, 45, 768)\n","Done 9 embeddings\n","Started\n","(1000, 45, 768)\n","Done 10 embeddings\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YBV7TuKY9dU7","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}